{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOAA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1457423, 51)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_details = pd.read_csv(\"results/combined_0.csv\", low_memory=False);\n",
    "event_details.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>END_YEARMONTH</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>...</th>\n",
       "      <th>END_RANGE</th>\n",
       "      <th>END_AZIMUTH</th>\n",
       "      <th>END_LOCATION</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EPISODE_NARRATIVE</th>\n",
       "      <th>EVENT_NARRATIVE</th>\n",
       "      <th>DATA_SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195004</td>\n",
       "      <td>28</td>\n",
       "      <td>1445</td>\n",
       "      <td>195004</td>\n",
       "      <td>28</td>\n",
       "      <td>1445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10096222</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.12</td>\n",
       "      <td>-99.2</td>\n",
       "      <td>35.17</td>\n",
       "      <td>-99.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195004</td>\n",
       "      <td>29</td>\n",
       "      <td>1530</td>\n",
       "      <td>195004</td>\n",
       "      <td>29</td>\n",
       "      <td>1530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10120412</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.90</td>\n",
       "      <td>-98.6</td>\n",
       "      <td>31.73</td>\n",
       "      <td>-98.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1800</td>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10104927</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.58</td>\n",
       "      <td>-75.7</td>\n",
       "      <td>40.65</td>\n",
       "      <td>-75.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  END_YEARMONTH  END_DAY  END_TIME  \\\n",
       "0           195004         28        1445         195004       28      1445   \n",
       "1           195004         29        1530         195004       29      1530   \n",
       "2           195007          5        1800         195007        5      1800   \n",
       "\n",
       "   EPISODE_ID  EVENT_ID         STATE  STATE_FIPS     ...      END_RANGE  \\\n",
       "0         NaN  10096222      OKLAHOMA        40.0     ...            0.0   \n",
       "1         NaN  10120412         TEXAS        48.0     ...            0.0   \n",
       "2         NaN  10104927  PENNSYLVANIA        42.0     ...            0.0   \n",
       "\n",
       "  END_AZIMUTH END_LOCATION BEGIN_LAT  BEGIN_LON END_LAT END_LON  \\\n",
       "0         NaN          NaN     35.12      -99.2   35.17  -99.20   \n",
       "1         NaN          NaN     31.90      -98.6   31.73  -98.60   \n",
       "2         NaN          NaN     40.58      -75.7   40.65  -75.47   \n",
       "\n",
       "  EPISODE_NARRATIVE EVENT_NARRATIVE DATA_SOURCE  \n",
       "0               NaN             NaN         PUB  \n",
       "1               NaN             NaN         PUB  \n",
       "2               NaN             NaN         PUB  \n",
       "\n",
       "[3 rows x 51 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_details.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 - summarize the property damage, by state, by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    250K\n",
       "1     25K\n",
       "2     25K\n",
       "Name: DAMAGE_PROPERTY, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_details_state['DAMAGE_PROPERTY'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The property damage column is not in number form. A quick glance shows that this field is suffixed with K representing thousand and M representing million. Next, we will convert this into number form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250000.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stolen from https://stackoverflow.com/questions/39684548/convert-the-string-2-90k-to-2900-or-5-2m-to-5200000-in-pandas-dataframe\n",
    "def value_to_float(x):\n",
    "    x = str(x)\n",
    "    if 'K' in x:\n",
    "        if len(x) > 1:\n",
    "            return float(x.replace('K', '')) * 1000\n",
    "        return 1000.0\n",
    "    if 'M' in x:\n",
    "        if len(x) > 1:\n",
    "            return float(x.replace('M', '')) * 1000000\n",
    "        return 1000000.0\n",
    "    if 'B' in x:\n",
    "        return float(x.replace('B', '')) * 1000000000\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_details['DAMAGE_PROPERTY_DOLLARS'] = event_details['DAMAGE_PROPERTY'].apply(value_to_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['OKLAHOMA', 'TEXAS', 'PENNSYLVANIA', 'NEBRASKA', 'MISSISSIPPI',\n",
       "       'NEW MEXICO', 'ARKANSAS', 'MISSOURI', 'CONNECTICUT', 'FLORIDA',\n",
       "       'NORTH CAROLINA', 'ALABAMA', 'KENTUCKY', 'MARYLAND', 'MINNESOTA',\n",
       "       'SOUTH DAKOTA', 'IOWA', 'LOUISIANA', 'OHIO', 'KANSAS',\n",
       "       'NORTH DAKOTA', 'INDIANA', 'COLORADO', 'SOUTH CAROLINA',\n",
       "       'WEST VIRGINIA', 'WYOMING', 'GEORGIA', 'WISCONSIN', 'ILLINOIS',\n",
       "       'TENNESSEE', 'NEW JERSEY', 'MICHIGAN', 'CALIFORNIA',\n",
       "       'MASSACHUSETTS', 'NEW HAMPSHIRE', 'OREGON', 'VIRGINIA', 'ARIZONA',\n",
       "       'NEW YORK', 'MONTANA', 'MAINE', 'VERMONT', 'UTAH', 'DELAWARE',\n",
       "       'IDAHO', 'WASHINGTON', 'HAWAII', 'RHODE ISLAND', 'NEVADA',\n",
       "       'PUERTO RICO', 'DISTRICT OF COLUMBIA', 'ALASKA', 'VIRGIN ISLANDS',\n",
       "       'GUAM', 'AMERICAN SAMOA', 'ATLANTIC SOUTH', 'LAKE ERIE',\n",
       "       'LAKE HURON', 'GULF OF MEXICO', 'LAKE ST CLAIR', 'E PACIFIC',\n",
       "       'HAWAII WATERS', 'LAKE MICHIGAN', 'ATLANTIC NORTH', 'LAKE ONTARIO',\n",
       "       'ST LAWRENCE R', 'LAKE SUPERIOR', 'GULF OF ALASKA', nan], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_details['STATE'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are non-states in our dataset, we need to be sure to filter these out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1424943, 52)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = pd.read_csv(\"states.csv\")\n",
    "#upper all states so they match file\n",
    "states['State'] = states['State'].apply(lambda x: x.upper())\n",
    "event_details_state = event_details[event_details['STATE'].isin(states['State'])]\n",
    "event_details_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We went from 1,457,423 to 1,424,943 after filtering non US states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_details_grouped = event_details_state.groupby(['STATE','YEAR'])['DAMAGE_PROPERTY_DOLLARS'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATE    YEAR\n",
       "ALABAMA  1950     27500.000\n",
       "         1951     35000.000\n",
       "         1952   5452500.000\n",
       "         1953   3070000.000\n",
       "         1954    607530.000\n",
       "Name: DAMAGE_PROPERTY_DOLLARS, dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_details_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# outputs to csv file\n",
    "event_details_grouped.to_csv(\"property_damage_summary.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
